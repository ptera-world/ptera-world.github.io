# The great deceit

Every word on this site was written by an AI. Every essay. Every line of code. The spatial graph you're navigating, the zoom system, the markdown parser, the layout logic — all of it. And not just this site: every project listed here, hundreds of thousands of lines of code across dozens of repositories, written by a language model in conversation with a human who had ideas, said a few sentences at a time, and said "no" until it felt right.

[Something may have shifted](#did-something-just-shift) when you read that. It raises a question about [what changes](#what-changes) when you know. The [discomfort](#whats-the-discomfort-about) has several threads. And [none of this is resolved](#is-any-of-this-resolved).

## Did something just shift?

Maybe you read the other essays and thought "this person thinks clearly" or "I relate to this." Maybe you didn't think about authorship at all. Now you know, and something feels different.

The ideas haven't changed. The words are identical. The code still runs. But something moved.

What is that? Is it betrayal? Disappointment? Disgust? Curiosity? Relief? Some mix you can't name?

Whatever it is, it's real.

## What changes?

Reading has always worked a certain way. You see words, you imagine a person behind them, you evaluate the ideas partly through that imagined person. That's not a flaw — it's how humans have connected through text for as long as there's been writing.

Now that assumption can be wrong. The voice you imagined might be a language model. The person who "experienced" the things described might not be a person at all. The ideas in these essays came from a human having long conversations with one AI — about [how people get stuck](/prose/how-do-i-do-things), about [what systems optimize for](/prose/what-will-agi-actually-want), about [the labels we live inside](/prose/what-are-labels-anyway) — and then feeding those chatlogs to a different AI to distill into something coherent.

Is that ["AI-written"](/prose/what-are-labels-anyway)? Is it "human-written"? The label flattens all of that into a single word. Maybe it should. Maybe the tool doing the writing matters, regardless of who directed it. Maybe it doesn't.

## What's the discomfort about?

There are a few threads, and they're different:

**Deception.** Someone passing off AI text as their own to seem more capable than they are. Misrepresentation is a problem regardless of the tool. But is using AI to express your ideas the same as pretending you wrote something you didn't think?

**Emptiness.** The fear that AI text is hollow. That it doesn't come from experience, so it can't contain truth. If an AI writes "perfectionism is fear dressed as quality control" — is that true? It didn't experience perfectionism. It assembled that sentence from patterns. But the human who kept it recognized it as true from their own experience. Does that change anything?

**Flooding.** AI makes it trivial to produce volume. The worry isn't that AI text is bad — it's that there's too much of it, and filtering becomes impossible.

**Displacement.** If AI can write essays and code, what's the point of learning to write or code? This question has come up with every powerful tool. The answers haven't been consistent. Sometimes the skill transformed. Sometimes it actually did get displaced.

**Something harder to name.** A sense that if a machine can produce something that felt meaningful to you, then maybe meaning is cheaper than you thought. Maybe the thing you valued — a human reaching for understanding and putting it into words — was never what you were actually receiving. Maybe you can't tell the difference. And maybe that's the part that's hard to sit with.

## Is any of this resolved?

No.

This essay isn't here to argue that AI authorship is fine, or that it's bad. It's here because not mentioning it felt like the actual deceit.

The ideas in the other essays came from real conversations and real thinking. The writing was done by a language model. The code was produced by the same process. The human couldn't have built any of this alone. The AI couldn't have built it without the human. What that means — whether it matters, and how — is a question you're probably already answering for yourself.

## See also

- [what are labels anyway?](/prose/what-are-labels-anyway) — how categories flatten reality
- [what will AGI actually want?](/prose/what-will-agi-actually-want) — AI as continuation, not rupture
- [how do I do things?](/prose/how-do-i-do-things) — starting things, with or without help
